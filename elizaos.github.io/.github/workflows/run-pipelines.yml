name: Run Pipelines

on:
  schedule:
    # Run at 23:00 UTC daily
    - cron: "0 23 * * *"
  workflow_dispatch: # Allow manual trigger
    inputs:
      force_ingest:
        description: "Force reingest of data"
        type: boolean
        default: false
        required: false
      force_process:
        description: "Force reprocessing/re-export of data"
        type: boolean
        default: false
        required: false
      force_summaries:
        description: "Force regeneration of summaries"
        type: boolean
        default: false
        required: false
      enable_project_summaries:
        description: "Generate project summaries"
        type: boolean
        default: true
        required: false
      enable_contributor_summaries:
        description: "Generate contributor summaries"
        type: boolean
        default: true
        required: false
      daily_summaries:
        description: "Enable daily summaries"
        type: boolean
        default: true
        required: false
      weekly_summaries:
        description: "Enable weekly summaries"
        type: boolean
        default: true
        required: false
      monthly_summaries:
        description: "Enable monthly summaries"
        type: boolean
        default: true
        required: false
      startDate:
        description: "Start date for data processing (format: YYYY-MM-DD)"
        type: string
        required: false
      endDate:
        description: "End date for data processing (format: YYYY-MM-DD)"
        type: string
        required: false

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
  PIPELINE_DATA_BRANCH: "_data" # Define branch name as environment variable
  DATA_DIR: "data"
jobs:
  ingest-export:
    name: Ingest/Export Pipeline
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write # Needed for pushing to branches

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      # Set common conditional variables
      - name: Set conditional variables
        id: set-vars
        run: |
          START_DATE_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.startDate != '' && format(' -a {0}', github.event.inputs.startDate) || '' }}"
          END_DATE_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.endDate != '' && format(' -b {0}', github.event.inputs.endDate) || '' }}"

          FORCE_INGEST_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_ingest == 'true' && ' -f' || '' }}"

          FORCE_PROCESS_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_process == 'true' && ' -f' || '' }}"

          echo "start_date_arg=$START_DATE_ARG" >> $GITHUB_ENV
          echo "end_date_arg=$END_DATE_ARG" >> $GITHUB_ENV
          echo "force_ingest_arg=$FORCE_INGEST_ARG" >> $GITHUB_ENV
          echo "force_process_arg=$FORCE_PROCESS_ARG" >> $GITHUB_ENV

      # Set up pipeline-data branch worktree
      - name: Setup pipeline-data branch
        uses: ./.github/actions/pipeline-data
        with:
          operation: setup
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}
          data_dir: ${{ env.DATA_DIR }}

      # Restore database from pipeline-data branch
      - name: Restore database
        uses: ./.github/actions/restore-db
        with:
          operation: restore
          dump_dir: ${{ env.DATA_DIR }}/dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite

      - name: Run ingest pipeline
        run: bun run pipeline ingest${{ env.force_ingest_arg }}${{ env.start_date_arg }}${{ env.end_date_arg }}

      - name: Run process pipeline
        run: bun run pipeline process${{ env.force_process_arg }}

      - name: Run export pipeline # Export everything missing + overwrite last 2 days to ensure overlap
        run: |
          bun run pipeline export${{ env.start_date_arg }}${{ env.end_date_arg }}${{ env.force_process_arg }}
          bun run pipeline export --days 2 -f

      # Dump SQLite database to diffable files before updating pipeline-data branch
      - name: Dump SQLite database
        uses: ./.github/actions/restore-db
        with:
          operation: dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite
          dump_dir: ${{ env.DATA_DIR }}/dump

      # Update pipeline-data branch with new data
      - name: Update pipeline-data branch
        uses: ./.github/actions/pipeline-data
        with:
          operation: update
          data_dir: ${{ env.DATA_DIR }}
          commit_message: "Ingest/export run: $(date -u +'%Y-%m-%d %H:%M')"
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}

      # Cleanup worktree (always runs)
      - name: Cleanup
        if: always()
        uses: ./.github/actions/pipeline-data
        with:
          operation: cleanup
          data_dir: ${{ env.DATA_DIR }}
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}

  generate-summaries:
    name: Generate Summaries
    needs: ingest-export
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write # Needed for pushing to branches
    # Skip summary generation if both project and contributor summaries are disabled in a manual run
    if: ${{ github.event_name != 'workflow_dispatch' || github.event.inputs.enable_project_summaries == 'true' || github.event.inputs.enable_contributor_summaries == 'true' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install --frozen-lockfile

      # Set common conditional variables
      - name: Set conditional variables
        id: set-vars
        run: |
          START_DATE_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.startDate != '' && format(' -a {0}', github.event.inputs.startDate) || '' }}"
          END_DATE_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.endDate != '' && format(' -b {0}', github.event.inputs.endDate) || '' }}"

          # Forced summary generation flag
          FORCE_SUMMARIES_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_summaries == 'true' && ' -f' || '' }}"

          # Summary interval flags
          DAILY_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.daily_summaries == 'true' && ' --daily' || '' }}"
          WEEKLY_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.weekly_summaries == 'true' && ' --weekly' || '' }}"
          MONTHLY_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.monthly_summaries == 'true' && ' --monthly' || '' }}"

          # For scheduled runs, enable all intervals
          if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
            DAILY_ARG=""
            WEEKLY_ARG=""
            MONTHLY_ARG=""
          fi

          INTERVAL_ARGS="$DAILY_ARG$WEEKLY_ARG$MONTHLY_ARG"

          echo "start_date_arg=$START_DATE_ARG" >> $GITHUB_ENV
          echo "end_date_arg=$END_DATE_ARG" >> $GITHUB_ENV
          echo "force_summaries_arg=$FORCE_SUMMARIES_ARG" >> $GITHUB_ENV
          echo "interval_args=$INTERVAL_ARGS" >> $GITHUB_ENV

      # Set up pipeline-data branch worktree
      - name: Setup pipeline-data branch
        uses: ./.github/actions/pipeline-data
        with:
          operation: setup
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}
          data_dir: ${{ env.DATA_DIR }}
      # Restore database from pipeline-data branch
      - name: Restore database
        uses: ./.github/actions/restore-db
        with:
          operation: restore
          dump_dir: ${{ env.DATA_DIR }}/dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite

      # Determine which summaries to run based on day of week or manual inputs
      - name: Check for summary generation
        id: summary-check
        run: |
          # By default, always run project summaries on scheduled runs
          RUN_PROJECT=true

          # For scheduled runs, only run contributor summaries on Sunday (day 7)
          if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
            DAY_OF_WEEK=$(date +%u)
            if [ "$DAY_OF_WEEK" = "7" ]; then
              RUN_CONTRIBUTOR=true
            else
              RUN_CONTRIBUTOR=false
            fi
          else
            # For manual runs, use input flags
            RUN_PROJECT="${{ github.event.inputs.enable_project_summaries == 'true' }}"
            RUN_CONTRIBUTOR="${{ github.event.inputs.enable_contributor_summaries == 'true' }}"
          fi

          echo "run_project=$RUN_PROJECT" >> $GITHUB_OUTPUT
          echo "run_contributor=$RUN_CONTRIBUTOR" >> $GITHUB_OUTPUT

      - name: Generate project summaries
        if: ${{ steps.summary-check.outputs.run_project == 'true' }}
        run: |
          bun run pipeline summarize -t project${{ env.start_date_arg }}${{ env.end_date_arg }}${{ env.force_summaries_arg }}${{ env.interval_args }}

      - name: Force regenerate recent project summaries
        if: ${{ github.event_name != 'workflow_dispatch' && steps.summary-check.outputs.run_project == 'true' }}
        run: |
          bun run pipeline summarize -t project -f -d 1

      - name: Generate contributor summaries
        if: ${{ steps.summary-check.outputs.run_contributor == 'true' }}
        run: |
          bun run pipeline summarize -t contributors${{ env.start_date_arg }}${{ env.end_date_arg }}${{ env.force_summaries_arg }}${{ env.interval_args }}

      - name: Force regenerate recent contributor summaries
        if: ${{ github.event_name != 'workflow_dispatch' && steps.summary-check.outputs.run_contributor == 'true' }}
        run: |
          bun run pipeline summarize -t contributors -f -d 1

      # Dump SQLite database to diffable files
      - name: Dump SQLite database
        uses: ./.github/actions/restore-db
        with:
          operation: dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite
          dump_dir: ${{ env.DATA_DIR }}/dump

      # Update pipeline-data branch with new summaries
      - name: Update pipeline-data branch with summaries
        uses: ./.github/actions/pipeline-data
        with:
          operation: update
          data_dir: ${{ env.DATA_DIR }}
          commit_message: "Summary generation (${{ steps.summary-check.outputs.run_contributor == 'true' && 'contributor ' || '' }} ${{ steps.summary-check.outputs.run_project == 'true' && 'project ' || '' }}): $(date -u +'%Y-%m-%d %H:%M')"
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}

      # Cleanup worktree (always runs)
      - name: Cleanup
        if: always()
        uses: ./.github/actions/pipeline-data
        with:
          operation: cleanup
          data_dir: ${{ env.DATA_DIR }}
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}
